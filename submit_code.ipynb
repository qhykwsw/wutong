{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python version: 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n",
      "NumPy version: 1.19.5\n",
      "pandas version: 1.2.2\n",
      "LightGBM version: 3.1.1\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import numpy as np\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import pandas as pd\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import lightgbm as lgb\n",
    "print(\"LightGBM version: {}\". format(lgb.__version__))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data_path = \"data\"\n",
    "\n",
    "# A榜原始数据\n",
    "data_a_df = pd.read_csv(os.path.join(data_path, \"data_a.csv\")).set_index('phone')\n",
    "data_a_df.replace('\\\\N', np.NaN, inplace=True)\n",
    "to_pred_a = pd.read_csv(os.path.join(data_path, \"to_pred_a.csv\")).set_index('phone')\n",
    "train_label = pd.read_csv(os.path.join(data_path, \"train_label.csv\")).set_index('phone')\n",
    "\n",
    "# B榜原始数据\n",
    "data_b_df = pd.read_csv(os.path.join(data_path, \"data_b.csv\")).set_index('phone')\n",
    "data_b_df.replace('\\\\N', np.NaN, inplace=True)\n",
    "to_pred_b = pd.read_csv(os.path.join(data_path, \"to_pred_b.csv\")).set_index('phone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从object转换为float类型, 方便计算\n",
    "f_features = ['if_family', 'gprs_fee', 'overrun_flux_fee', 'out_actvcall_dur', 'actvcall_fee',\n",
    "       'out_activcall_fee', 'monfix_fee', 'gift_acct_amt', 'call_cnt',\n",
    "       'up_flux', 'down_flux', 'p2psms_up_cnt',\n",
    "       'p2psms_cmnct_fee', 'p2psms_pkg_fee']\n",
    "\n",
    "data_a_df[f_features] = data_a_df[f_features].astype('float')\n",
    "data_b_df[f_features] = data_b_df[f_features].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离训练与测试数据, 训练数据主体是1月, 测试数据主体是3月\n",
    "train_val = pd.merge(data_a_df, train_label, on='phone', how='inner')\n",
    "X_train_01 = train_val[train_val['month']==202001]\n",
    "X_train_02 = train_val[train_val['month']==202002]\n",
    "\n",
    "# test = pd.merge(data_a_df, to_pred_a, on='phone', how='inner') # A榜\n",
    "test = pd.merge(data_b_df, to_pred_b, on='phone', how='inner') # B榜\n",
    "X_test_03 = test[test['month']==202003]\n",
    "X_test_04 = test[test['month']==202004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把df2的某特征拼接到df1上(保持df1原特征不变)\n",
    "def conact_feature(df1, df2, feature):\n",
    "    df2 = df2[[feature]]\n",
    "    df = pd.merge(df1, df2, on='phone', how='inner')\n",
    "    return df\n",
    "\n",
    "# 把df2的某特征值累加到df1上, 在处理NaN值上, 只要有一个为NaN, 累加值就为另一个不为NaN的值\n",
    "def cumulative(df1, df2, feature):\n",
    "    df1[feature] = np.where(pd.isnull(df2[feature]), df1[feature], df2[feature]+np.where(pd.isnull(df1[feature]), 0, df1[feature]))\n",
    "    return df1\n",
    "\n",
    "# 把df1和df2的特征取并集, 仅用于处理类别变量\n",
    "def combine_cat_feature(df1, df2, feature):\n",
    "    df1[feature].replace(np.NaN, 0, inplace=True)\n",
    "    df2[feature].replace(np.NaN, 0, inplace=True)\n",
    "    df1[feature] += df2[feature]\n",
    "    df1[feature].replace(2, 1, inplace=True)\n",
    "    df1[feature].replace(0, np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建训练集特征\n",
    "def train_feature_engineering(df1, df2):\n",
    "    df1 = conact_feature(df1, df2, 'monfix_fee')\n",
    "    combine_cat_feature(df1, df2, 'if_family')\n",
    "    return df1\n",
    "\n",
    "# 构建测试集特征\n",
    "def test_feature_engineering(df1, df2):\n",
    "    df1 = conact_feature(df1, df2, 'monfix_fee')\n",
    "    combine_cat_feature(df1, df2, 'if_family')\n",
    "    df1 = cumulative(df1, df2, 'chrg_cnt')\n",
    "    df1 = cumulative(df1, df2, 'gprs_fee')\n",
    "    df1 = cumulative(df1, df2, 'overrun_flux_fee')\n",
    "    df1 = cumulative(df1, df2, 'p2psms_up_cnt')\n",
    "    df1 = cumulative(df1, df2, 'p2psms_cmnct_fee')\n",
    "    df1 = cumulative(df1, df2, 'p2psms_pkg_fee')\n",
    "    return df1\n",
    "\n",
    "X_train = train_feature_engineering(X_train_01, X_train_02)\n",
    "X_test = test_feature_engineering(X_test_03, X_test_04)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['if_family', 'if_group', 'chrg_cnt', 'gprs_fee', 'overrun_flux_fee',\n",
       "       'out_actvcall_dur', 'actvcall_fee', 'out_activcall_fee', 'monfix_fee_x',\n",
       "       'gift_acct_amt', 'call_cnt', 'sms_inpkg_ind', 'p2psms_up_cnt',\n",
       "       'p2psms_cmnct_fee', 'p2psms_pkg_fee', 'monfix_fee_y'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# 转换下列三个特征为类别特征\n",
    "cat_cols = ['if_family', 'if_group', 'sms_inpkg_ind']\n",
    "for cat_col in cat_cols:\n",
    "    X_train[cat_col] = X_train[cat_col].astype('category')\n",
    "    X_test[cat_col] = X_test[cat_col].astype('category')\n",
    "    \n",
    "y = X_train['label']\n",
    "\n",
    "# 丢弃以下特征\n",
    "drop_cols = ['label', 'month', 'chrg_amt', 'up_flux', 'down_flux']\n",
    "X_train.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "# 实际训练用到的所有特征\n",
    "features = X_train.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Info] Number of positive: 4787, number of negative: 341943\n",
      "[LightGBM] [Info] Total Bins 2835\n",
      "[LightGBM] [Info] Number of data points in the train set: 346730, number of used features: 16\n",
      "[LightGBM] [Info] Number of positive: 4787, number of negative: 341943\n",
      "[LightGBM] [Info] Total Bins 2835\n",
      "[LightGBM] [Info] Number of data points in the train set: 346730, number of used features: 16\n",
      "[LightGBM] [Info] Number of positive: 4787, number of negative: 341943\n",
      "[LightGBM] [Info] Total Bins 2835\n",
      "[LightGBM] [Info] Number of data points in the train set: 346730, number of used features: 16\n",
      "[LightGBM] [Info] Number of positive: 4788, number of negative: 341943\n",
      "[LightGBM] [Info] Total Bins 2835\n",
      "[LightGBM] [Info] Number of data points in the train set: 346731, number of used features: 16\n",
      "[LightGBM] [Info] Number of positive: 4787, number of negative: 341944\n",
      "[LightGBM] [Info] Total Bins 2835\n",
      "[LightGBM] [Info] Number of data points in the train set: 346731, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013806 -> initscore=-4.268740\n",
      "[LightGBM] [Info] Start training from score -4.268740\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013806 -> initscore=-4.268740\n",
      "[LightGBM] [Info] Start training from score -4.268740\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013806 -> initscore=-4.268740\n",
      "[LightGBM] [Info] Start training from score -4.268740\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013809 -> initscore=-4.268531\n",
      "[LightGBM] [Info] Start training from score -4.268531\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.013806 -> initscore=-4.268743\n",
      "[LightGBM] [Info] Start training from score -4.268743\n",
      "[100]\tcv_agg's auc: 0.999487 + 8.51327e-05\tcv_agg's binary_logloss: 0.0237401 + 9.57759e-05\tcv_agg's binary_error: 0.0138067 + 4.56719e-06\n",
      "[200]\tcv_agg's auc: 0.999522 + 9.42785e-05\tcv_agg's binary_logloss: 0.0147933 + 0.000117079\tcv_agg's binary_error: 0.00257953 + 0.00021242\n",
      "[300]\tcv_agg's auc: 0.999526 + 9.6175e-05\tcv_agg's binary_logloss: 0.0104983 + 0.000147107\tcv_agg's binary_error: 0.00220575 + 0.000125189\n",
      "[400]\tcv_agg's auc: 0.999528 + 9.73648e-05\tcv_agg's binary_logloss: 0.00820424 + 0.000175751\tcv_agg's binary_error: 0.00213884 + 0.000175811\n",
      "[500]\tcv_agg's auc: 0.999522 + 0.00011362\tcv_agg's binary_logloss: 0.00693506 + 0.000203831\tcv_agg's binary_error: 0.00196348 + 0.000103795\n",
      "[600]\tcv_agg's auc: 0.999526 + 0.000112869\tcv_agg's binary_logloss: 0.00621259 + 0.000230051\tcv_agg's binary_error: 0.00195426 + 9.66792e-05\n",
      "[700]\tcv_agg's auc: 0.999528 + 0.000114409\tcv_agg's binary_logloss: 0.00578917 + 0.000250134\tcv_agg's binary_error: 0.00194272 + 0.000101251\n",
      "[800]\tcv_agg's auc: 0.999543 + 9.64151e-05\tcv_agg's binary_logloss: 0.00553995 + 0.000266799\tcv_agg's binary_error: 0.00193118 + 9.58493e-05\n",
      "[900]\tcv_agg's auc: 0.999558 + 7.27887e-05\tcv_agg's binary_logloss: 0.00538993 + 0.00028053\tcv_agg's binary_error: 0.00191503 + 0.00010522\n",
      "[1000]\tcv_agg's auc: 0.999559 + 7.36171e-05\tcv_agg's binary_logloss: 0.0053008 + 0.000291321\tcv_agg's binary_error: 0.00191965 + 0.000108606\n",
      "[1100]\tcv_agg's auc: 0.99956 + 7.41213e-05\tcv_agg's binary_logloss: 0.00524829 + 0.000298899\tcv_agg's binary_error: 0.00191503 + 0.000113261\n",
      "[1200]\tcv_agg's auc: 0.99956 + 7.16325e-05\tcv_agg's binary_logloss: 0.00521827 + 0.000304326\tcv_agg's binary_error: 0.00190811 + 0.000119793\n",
      "[1300]\tcv_agg's auc: 0.999562 + 6.55588e-05\tcv_agg's binary_logloss: 0.00520117 + 0.000307943\tcv_agg's binary_error: 0.0019035 + 0.000118991\n",
      "[1400]\tcv_agg's auc: 0.999563 + 6.45076e-05\tcv_agg's binary_logloss: 0.00519146 + 0.00031036\tcv_agg's binary_error: 0.00189888 + 0.000121558\n",
      "[1500]\tcv_agg's auc: 0.999563 + 6.4615e-05\tcv_agg's binary_logloss: 0.00518893 + 0.000312122\tcv_agg's binary_error: 0.00189888 + 0.000121558\n",
      "[1600]\tcv_agg's auc: 0.999562 + 6.54941e-05\tcv_agg's binary_logloss: 0.00519129 + 0.000314065\tcv_agg's binary_error: 0.00190119 + 0.000118857\n",
      "[1700]\tcv_agg's auc: 0.99956 + 6.47884e-05\tcv_agg's binary_logloss: 0.00519546 + 0.000313872\tcv_agg's binary_error: 0.0019035 + 0.000116276\n",
      "[1800]\tcv_agg's auc: 0.999559 + 6.34822e-05\tcv_agg's binary_logloss: 0.00520173 + 0.000314901\tcv_agg's binary_error: 0.00189888 + 0.000119793\n",
      "[1900]\tcv_agg's auc: 0.999557 + 6.24572e-05\tcv_agg's binary_logloss: 0.00521132 + 0.000315873\tcv_agg's binary_error: 0.0019035 + 0.000116276\n",
      "[2000]\tcv_agg's auc: 0.999556 + 6.23191e-05\tcv_agg's binary_logloss: 0.00521815 + 0.000316139\tcv_agg's binary_error: 0.00189888 + 0.000119793\n",
      "binary_logloss: 0.005218147129318608\n",
      "binary_error:   0.0018988812359969315\n",
      "auc:            0.9995559824586373\n"
     ]
    }
   ],
   "source": [
    "# 使用LightGBM训练模型\n",
    "dtrain = lgb.Dataset(X_train, y, free_raw_data=False)\n",
    "NFOLD = 5\n",
    "SEED = 2\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'force_row_wise': True,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.005,\n",
    "    'subsample': 0.8,\n",
    "    'subsample_freq':3,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'num_leaves': 55,\n",
    "    'max_depth': 14,\n",
    "    'n_jobs': 16,\n",
    "    'min_child_samples':20,\n",
    "    'min_child_weight': 0.001,\n",
    "    'min_split_gain': 0.0,\n",
    "    'metric': ['auc', 'binary_logloss', 'binary_error'],\n",
    "}\n",
    "hist = lgb.cv(\n",
    "    params=lgb_params,\n",
    "    train_set=dtrain,\n",
    "    categorical_feature=cat_cols,\n",
    "    num_boost_round=2000,\n",
    "    nfold=NFOLD,\n",
    "    return_cvbooster=True,\n",
    "    stratified=True,\n",
    "    shuffle=True,\n",
    "    verbose_eval=100,\n",
    "    seed=SEED\n",
    ")\n",
    "print('binary_logloss: {}'.format(hist['binary_logloss-mean'][-1]))\n",
    "print('binary_error:   {}'.format(hist['binary_error-mean'][-1]))\n",
    "print('auc:            {}'.format(hist['auc-mean'][-1]))\n",
    "predictions_lgb = np.array(hist['cvbooster'].predict(X_test[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "第 1 折:\n",
      "阈值选择 0.85 时, 预测有 2605 个fraud用户:\n",
      "阈值选择 0.86 时, 预测有 2590 个fraud用户:\n",
      "阈值选择 0.87 时, 预测有 2590 个fraud用户:\n",
      "阈值选择 0.88 时, 预测有 2589 个fraud用户:\n",
      "阈值选择 0.89 时, 预测有 2579 个fraud用户:\n",
      "阈值选择 0.9 时, 预测有 2576 个fraud用户:\n",
      "阈值选择 0.91 时, 预测有 2205 个fraud用户:\n",
      "阈值选择 0.92 时, 预测有 2205 个fraud用户:\n",
      "阈值选择 0.93 时, 预测有 2205 个fraud用户:\n",
      "阈值选择 0.94 时, 预测有 2205 个fraud用户:\n",
      "第 2 折:\n",
      "阈值选择 0.85 时, 预测有 2601 个fraud用户:\n",
      "阈值选择 0.86 时, 预测有 2601 个fraud用户:\n",
      "阈值选择 0.87 时, 预测有 2586 个fraud用户:\n",
      "阈值选择 0.88 时, 预测有 2586 个fraud用户:\n",
      "阈值选择 0.89 时, 预测有 2586 个fraud用户:\n",
      "阈值选择 0.9 时, 预测有 2214 个fraud用户:\n",
      "阈值选择 0.91 时, 预测有 2205 个fraud用户:\n",
      "阈值选择 0.92 时, 预测有 2205 个fraud用户:\n",
      "阈值选择 0.93 时, 预测有 1853 个fraud用户:\n",
      "阈值选择 0.94 时, 预测有 1853 个fraud用户:\n",
      "第 3 折:\n",
      "阈值选择 0.85 时, 预测有 2594 个fraud用户:\n",
      "阈值选择 0.86 时, 预测有 2579 个fraud用户:\n",
      "阈值选择 0.87 时, 预测有 2579 个fraud用户:\n",
      "阈值选择 0.88 时, 预测有 2578 个fraud用户:\n",
      "阈值选择 0.89 时, 预测有 2577 个fraud用户:\n",
      "阈值选择 0.9 时, 预测有 2577 个fraud用户:\n",
      "阈值选择 0.91 时, 预测有 2205 个fraud用户:\n",
      "阈值选择 0.92 时, 预测有 1853 个fraud用户:\n",
      "阈值选择 0.93 时, 预测有 1853 个fraud用户:\n",
      "阈值选择 0.94 时, 预测有 1845 个fraud用户:\n",
      "第 4 折:\n",
      "阈值选择 0.85 时, 预测有 2593 个fraud用户:\n",
      "阈值选择 0.86 时, 预测有 2583 个fraud用户:\n",
      "阈值选择 0.87 时, 预测有 2568 个fraud用户:\n",
      "阈值选择 0.88 时, 预测有 2568 个fraud用户:\n",
      "阈值选择 0.89 时, 预测有 2568 个fraud用户:\n",
      "阈值选择 0.9 时, 预测有 2567 个fraud用户:\n",
      "阈值选择 0.91 时, 预测有 2205 个fraud用户:\n",
      "阈值选择 0.92 时, 预测有 2205 个fraud用户:\n",
      "阈值选择 0.93 时, 预测有 1855 个fraud用户:\n",
      "阈值选择 0.94 时, 预测有 1853 个fraud用户:\n",
      "第 5 折:\n",
      "阈值选择 0.85 时, 预测有 2602 个fraud用户:\n",
      "阈值选择 0.86 时, 预测有 2593 个fraud用户:\n",
      "阈值选择 0.87 时, 预测有 2583 个fraud用户:\n",
      "阈值选择 0.88 时, 预测有 2583 个fraud用户:\n",
      "阈值选择 0.89 时, 预测有 2568 个fraud用户:\n",
      "阈值选择 0.9 时, 预测有 2568 个fraud用户:\n",
      "阈值选择 0.91 时, 预测有 2205 个fraud用户:\n",
      "阈值选择 0.92 时, 预测有 1853 个fraud用户:\n",
      "阈值选择 0.93 时, 预测有 1845 个fraud用户:\n",
      "阈值选择 0.94 时, 预测有 1845 个fraud用户:\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "for i in range(NFOLD):\n",
    "    predictions_lgb_i = predictions_lgb[i]\n",
    "    print(\"第 {} 折:\".format(i+1))\n",
    "    for j in range(85, 95, 1):\n",
    "        threshold = j/100\n",
    "        fraud_list = np.where(predictions_lgb_i < threshold, 0, 1)\n",
    "        print('阈值选择 {} 时, 预测有 {} 个fraud用户:'.format(threshold, sum(fraud_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "使用规则前, 预测有 2576 个fraud用户\n"
     ]
    }
   ],
   "source": [
    "# 没有使用5折交叉验证的平均值, 而是用了测试效果最好的第一折的结果\n",
    "# 根据经验阈值选择0.9时结果最好, 如果在使用规则前提交, 在线A榜F1成绩: 0.96318, B榜F1成绩: 0.960016\n",
    "threshold = 0.9\n",
    "X_test['label'] = np.where(predictions_lgb[0] < threshold, 0, 1)\n",
    "submit = pd.merge(X_test_04.drop('label', axis=1), X_test['label'], on='phone', how='inner')\n",
    "print('使用规则前, 预测有 {} 个fraud用户'.format(sum(submit['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用4月数据将错分为fraud的用户恢复正常, 依据经验设置具体规则\n",
    "submit.loc[submit[(submit['label']==1) & (submit['out_activcall_fee']>0)].index, 'label'] = 0\n",
    "submit.loc[submit[(submit['label']==1) & (submit['out_actvcall_dur']>20)].index, 'label'] = 0\n",
    "submit.loc[submit[(submit['label']==1) & (submit['actvcall_fee']>5)].index, 'label'] = 0\n",
    "submit.loc[submit[(submit['label']==1) & (submit['gift_acct_amt']>8)].index, 'label'] = 0\n",
    "submit.loc[submit[(submit['label']==1) & (submit['call_cnt']>0)].index, 'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "使用规则后, 阈值选择 0.9 时, 预测有 2564 个fraud用户\n"
     ]
    }
   ],
   "source": [
    "# 在使用规则后提交, B榜F1成绩: 0.961095\n",
    "submit = submit.reset_index()[['phone','label']]\n",
    "submit.to_csv('./Single_model_results/LightGBM_{}_{}.csv'.format(threshold, sum(submit['label'])), index=False, encoding=\"utf-8\")\n",
    "print('使用规则后, 阈值选择 {} 时, 预测有 {} 个fraud用户'.format(threshold, sum(submit['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}